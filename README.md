Multi-Class Text Classification Using Word Representations and ML/NN Models

This project presents a comparative study of 22 machine learning and neural network models-including Logistic Regression, Naive Bayes, Random Forest, DNN, RNN, GRU, LSTM, and their bidirectional variants-for multi-class text classification using BoW, TF-IDF, GloVe, and Skip-gram embeddings.The work highlights key performance differences between traditional ML approaches and advanced neural network architectures.
